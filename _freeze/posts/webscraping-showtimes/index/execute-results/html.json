{
  "hash": "27ac4afa121e521410e4fce3668a61d0",
  "result": {
    "markdown": "---\ntitle: Webscraping movie showtimes with Scrapy\ndraft: true\ndescription: The algorithm got me again\ncategories:\n  - webscraping\n  - python\n  - raspberry pi\nexecute:\n  eval: false\n---\n\nI'm a flawed human being and therefore susceptible to ads I receive on the internet. One day I was scrolling and stumbled upon this little gadget by Pimoroni: the [Inky Frame 7.3\\\"](https://shop.pimoroni.com/products/inky-frame-7-3?variant=40541882056787), a fun little e-ink screen that you can program with micropython. I bought it without much a plan for what I would use it for, but thought it would be a fun excuse to practice my python skills. I soon got the idea to combine my loves: I spend all my free time and money at the [Belcourt Theatre](https://www.belcourt.org) in Nashville, and thought it would be cool to use the screen as a little display that shows the showtimes for the day.\n\nAccomplishing this means several things have to happen:\n\n1.  Webscrape the showtimes from the theater's website\n2.  Format the showtimes into an image that works well on the Inky Frame display\n3.  Push the image output to the Inky Frame\n4.  Schedule all of the above to run daily automatically\n\nHere I go through what I did for each of these steps. All the code is available on [GitHub](https://github.com/lindsayevanslee/inky-frame).\n\n# Web scrape the showtimes\n\nTo webscrape the showtimes, I used the popular python package `Scrapy`. There is a really useful and fun course on LinkedIn Learning by Ryan Mitchell called [\"Web Scraping with Python\"](https://www.linkedin.com/learning/web-scraping-with-python/hello-world-with-scrapy?u=103732282), which is where I first learned how to do this. She also has a book [\"Web scraping with Python\"](https://www.oreilly.com/library/view/web-scraping-with/9781491985564/) that is super informative. I'll leave most of the detail to her, but here is the gist:\n\nFirst install `Scrapy`:\n\n\n```{bash}\npip install Scrapy\n```\n\n\nThen you initialize a new project like so:\n\n\n```{bash}\nscrapy startproject belcourt\n```\n\n\nNavigate to the new project folder and initialize a spider (a \"spider\" is the program that will do all the scraping that you specify). Here I'm creating a spider called `showtimes` that will scrape the website `belcourt.org`:\n\n\n```{bash}\ncd belcourt\nscrapy genspider showtimes belcourt.org\n```\n\n\nIn the `items.py` script that is generated, I defined the structure of the output that I wanted by defining a new class called `BelcourtItem`.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport scrapy\n\nclass BelcourtItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    currenttime = scrapy.Field()\n    date = scrapy.Field()\n    shows = scrapy.Field()\n```\n:::\n\n\nIn the `showtimes.py` script in the `spiders` folder, specify which content from the website should be pulled into your output object of class `BelcourtItem`. This involves inspecting the html of the website and finding the relevant elements. See Ryan Mitchell's course/book for tips on how to do this. I also suggest learning more about searching for HTML elements with XPATH--[this YouTube video](https://www.youtube.com/watch?v=NhG__BL8zFo&list=PLSao4Yl0-ZqMIEG604vsNJc1i5X8YUDar&index=1) was the best resource I've come across.\n\nTo run the spider, navigate the console to the `spiders` folder and run spider like below. This will print the output to a json file called `output_showtimes.json`:\n\n\n```{bash}\ncd belcourt/spiders\nscrapy runspider showtimes.py -O output_showtimes.json\n```\n\n\nYou can see what this json file looks like in my GitHub repository.\n\nVoila! Easy! Now we need to take the data from this json file and turn it into a fairly attractive jpg.\n\n# Format the output into an image\n\nConverting this json into a jpg mostly involved getting familiar with the `Pillow` python package. It can be installed like so:\n\n\n```{bash}\npip install Pillow\n```\n\n\nThe script I wrote is called `belcourt_generate_image.py`, and you can find it in the GitHub repository. \n\nFirst you read in the json output produced by the spider. Then specify some basics like the dimensions, title and subtitle and fonts. The dimensions match what is specified by Pimoroni in their [\"Getting Started with Inky Frame\"](https://learn.pimoroni.com/article/getting-started-with-inky-frame) resource. I read the fonts directly from ttf files which are also loaded into the repository. I also loaded the Belcourt logo so I could use it in my output.\n\nThe rest of the script is essentially telling python where exactly to place the different elements of the image. Finally, the output is saved to a jpg. One important note is that it is important that the resulting jpg must not be progressive. The frame can't handle it otherwise for some reason:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nbackground.save('result.jpg', progressive = False)\n```\n:::\n\n\nNow that we've got a jpg, time to get it on the screen!\n\n# Load image into Inky Frame\n\nHere is where we start getting into slightly uncharted territory. \n\nhttps://learn.pimoroni.com/article/getting-started-with-inky-frame#displaying-images\n\nload jpg to inky frame\n\nhttps://www.python-engineer.com/posts/run-python-github-actions/ https://crontab.guru\n\nGitHub Actions\n\nSettings \\> Actions \\> General \\> Workflow Permissions \\> Read and write permissions\n\nUse pimoroni example as basis for loading to screen: https://github.com/pimoroni/pimoroni-pico/blob/main/micropython/examples/inky_frame/inky_frame_xkcd_daily.py\n\ntried to load directly from raw jpg output in github repo, doesn't work--gives \"can't read jpg\" error\n\ntrying to load from a different website.....-\\> unoptimized version just gets stuck and doesn't finish, using optimized version does work!!!!\n\nlink to github output -\\> works! but repo must be public! (DUH)\n\nmaybe linking directly to github will work now with public repo -\\> nope, gives error about redirects\n\ntry again to use unoptimized version, loading from github from a different site -\\> works???\n\nalso works using the image copy of unoptimized version. so not sure why it wasn't working before.....\n\nembedding an iframe to jpg link doesn't work\n\ncreate github pages on inky frame repo and try to link to it from there -\\> works! this seems like it would be the best final solution\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}