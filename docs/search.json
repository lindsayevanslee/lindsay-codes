[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog acts as a Joycean stream-of-consciousness record of the random tech-y things I’m experimenting with and learning. It started because I bought this domain name on a whim and thought it was too cool to not do something with. The purpose is to prevent things falling out of my goldfish brain. If you’re reading this, I hope it benefits you too, though there’s certainly no guarantee.\nPlease visit my website or LinkedIn for a slightly more professional persona."
  },
  {
    "objectID": "posts/apple-watch/index.html",
    "href": "posts/apple-watch/index.html",
    "title": "Analyze health data from the Apple Watch",
    "section": "",
    "text": "I have a doctor’s appointment soon, and I wanted to see if health data from my Apple Watch could help inform our conversation. The Health app has interesting visualizations out of the box, but I wanted to do something a tad more complicated.\nTo download the data from the Apple Health app on your iPhone, go to the Health app, click on your profile picture in the top right corner, and select “Export All Health Data”. This will create a zip file that you can share with yourself. Next download the zip file and extract the contents. The important file in this extract is export.xml. I have this file saved in a folder data/apple_health_export in my GitHub repository. I have the data folder in the .gitignore file so that the data is not uploaded to this GitHub repository.\nIt’s not super easy to work with the data in xml format, so I wanted to convert this data to csv format. Luckily I found someone else’s code to do exactly this. I saved their parsing function as convert_xml_to_csv.py in my GitHub repository for this analysis.\nTo see the xml data as json within the terminal, run the following command in the Terminal:\npython convert_xml_to_csv.py data/apple_health_export/export.xml\nTo convert the xml data to a csv file, run the following command in the Terminal:\npython convert_xml_to_csv.py data/apple_health_export/export.xml | jq -r '[.startDate, .endDate, .type, .unit, .value] | @csv' &gt; data/apple_health_export/export.csv\nThis requires the JSON parser jq to be installed. I installed jq via Homebrew on my Mac with: brew install jq.\nWith the data in a usable format, it’s easy to make all kinds of nice graphs. I have a couple examples in my script print_spo2_graph.R in the repository. The pdf output is saved to an output folder which is also in .gitignore (sorry, nosy nellies!)\nNow I’m all ready for my appointment. I’m sure my doctor will think this is useful and not a waste of everyone’s time."
  },
  {
    "objectID": "posts/get-started-with-conda/index.html",
    "href": "posts/get-started-with-conda/index.html",
    "title": "Get started with conda",
    "section": "",
    "text": "My python skills aren’t super strong yet, but they’re strong enough to know that environment management is key, and it’s an area I know next to nothing about. I figured it’s time to at least learn the basics.\nThere seem to be two main tools for environment management in python: conda and venv. I tried to do a little bit of research to see what the pros and cons are of each. This reddit thread was useful, and this blog post linked to from that thread was helpful too. It seems like the main differences are that venv’s main purpose is for isolating a virtual environment, while conda provides more help managing packages for your project. It appears conda helps you by installing commonly used packages, which may not be suitable in industry/production settings. I’m just playing around and need all the help I can get, so I decided to take a crack at conda first.\nThere are two flavors of conda: anaconda and miniconda. anaconda comes with a lot more packages and also an app to manage the packages. miniconda is more stripped-down. I decided to try miniconda first, because I didn’t like the idea of installing more apps on my computer.\nI’m on a Mac, and the savior for any amateur programmer on a Mac is Homebrew, a wonderful package manager for macOS which makes it so much easier to install all the little programs and utilities needed to code stuff. I can’t remember all the things I’ve installed with it, but it always seems to be there to save the day when I’m having issues installing python or R packages. Luckily it saves the day here again: you can install miniconda with Homebrew as well. This Medium article helped me figure out how. All I needed to do was run this in the Terminal:\n\nbrew install --cask miniconda\nconda init zsh\n\nThen restart the Terminal. I tested the install worked by running conda, which didn’t return any errors, which is what I wanted to see.\nNow to try our first environment! I used my inky-frame project as a test case (check out my post about it here). I first wanted to try the more point-and-click way to create a python environment in VS Code. It says by using the “Python: Create Environment” command from the Control Palette, it should automatically detect an existing requirements.txt file to install the packages you need to create the environment. I tried this first, but after trying to run a script in the new environment, I got “package not found” errors, meaning it didn’t seem to actually install the necessary packages listed in requirements.txt.\nNext I tried creating the conda environment using the command line by running:\n\nconda install --file requirements.txt\n\nBut this still didn’t seem to install the packages. It gave a long error message like this:\n\nChannels:\n - defaults\nPlatform: osx-64\nCollecting package metadata (repodata.json): done\nSolving environment: failed\n\nLibMambaUnsatisfiableError: Encountered problems while solving:\n  - nothing provides requested asttokens 2.2.1\n  - nothing provides requested charset-normalizer 3.1.0\n  ...\n\nCould not solve for environment specs\nThe following packages are incompatible\n├─ appnope 0.1.3  is installable and it requires\n│  └─ python &gt;=3.12,&lt;3.13.0a0 , which can be installed;\n├─ asttokens 2.2.1  does not exist (perhaps a typo or a missing channel);\n...\n\n(where ... means multiple lines of the same pattern for various other packages). I was stumped so I pasted this error into GitHub Copilot and asked what it meant. It told me I may need to add a “channel” for conda to search in; I only had the defaults channel added, which didn’t seem to have all the packages I was asking for. It suggested I add the conda-forge channel. I did this by running:\n\nconda config --add channels conda-forge\n\nAfter doing this, I tried to create the environment again, and I got a new but more promising error. This time it said there were only two packages it wasn’t able to install (pure-eval==0.2.2 and stack-data==0.6.2). It suggested searching https://anaconda.org to see if I could find a channel they were in that I could add. I tried searching but couldn’t find any channels they were in.\nLuckily from the conda documentation I saw that you can still install packages with pip while using conda. I wasn’t sure how to tell conda to use pip using a requirements.txt file, but it seemed like it was easier using a environment.yml file instead. I asked GitHub Copilot to help me convert my requirements.txt to a environment.yml file, then tried to create the environment again with:\n\nconda env create -f environment.yml\n\nI still got an error, but luckily it was a small one: I needed to use single = for specifying versions for the dependencies in environment.yml, while I needed to use == for specifying versions for packages installed with pip. Fixing this, I reran the command, and finally I created a working conda environment! I also retried the point-and-click way to create an environment in VS Code, it also worked, automatically using the environment.yml file to install the necessary packages.\nFor the moment I’m keeping both requirements.txt and environment.yml in my repo because requirements.txt is used in the GitHub Actions I have set up. I also noticed that my GitHub Actions use different python version than what I’m using locally in this new conda environment. But I’ll take a few moments to bask in my win and will worry about that later."
  },
  {
    "objectID": "posts/webscraping-showtimes/index.html",
    "href": "posts/webscraping-showtimes/index.html",
    "title": "Making my own box office sign with Scrapy and an Inky Frame",
    "section": "",
    "text": "I’m a flawed human being and therefore susceptible to ads I receive on the internet. One day I was scrolling and stumbled upon this little gadget by Pimoroni: the Inky Frame 7.3”, a fun little e-ink screen that you can program with micropython. I bought it without much a plan for what I would use it for, but thought it would be a fun excuse to practice my python skills. I soon got the idea to combine my loves: I spend all my free time and money at the Belcourt Theatre in Nashville, and thought it would be cool to use the screen as a little display that shows the showtimes for the day.\nAccomplishing this means several things have to happen:\nHere I go through what I did for each of these steps. All the code is available on GitHub."
  },
  {
    "objectID": "posts/webscraping-showtimes/index.html#automate-the-jpg-update",
    "href": "posts/webscraping-showtimes/index.html#automate-the-jpg-update",
    "title": "Making my own box office sign with Scrapy and an Inky Frame",
    "section": "Automate the jpg update",
    "text": "Automate the jpg update\nGitHub Actions can be used to execute scripts on a schedule and make commits to the repository. I used this guide to set up a GitHub Action that would run the spider and generate the jpg every day in the early morning. The syntax for defining the schedule is called cron, and this website is super helpful for figuring out how to configure the cron syntax to do what you want.\nThis GitHub Action requires giving the workflows read/write permissions by enabling: Settings &gt; Actions &gt; General &gt; Workflow Permissions &gt; Read and write permissions. The workflow is defined by a YAML file that I’ve called .github/workflows/actions.yml in the GitHub repository. The script runs the spider, runs the belcourt_generate_image.py script, and then commits the resulting jpg to the repository.\nA second GitHub Action is needed to update the GitHub Pages deployment every time the jpg is updated. By going to Settings &gt; Pages, you can configure the deployment of the webpage. GitHub automatically provides an Action template for you, and there is additional detail in the documentation. One change I made to the YAML file was to schedule the deployment to run after the first action that updates the jpg. I wanted to do this by triggering the deployment after the new changes were committed to the repository. I found this blog that was trying to do the same thing, but I couldn’t get it to work. It’s got something to do with setting SSH keys, which I’ll figure out at a later date. Instead I again used cron to schedule the deployment to run half an hour after the first action, which should be enough time for the jpg generation to finish."
  },
  {
    "objectID": "posts/webscraping-showtimes/index.html#automate-the-inky-frame-refresh",
    "href": "posts/webscraping-showtimes/index.html#automate-the-inky-frame-refresh",
    "title": "Making my own box office sign with Scrapy and an Inky Frame",
    "section": "Automate the Inky Frame refresh",
    "text": "Automate the Inky Frame refresh\nThe final step in this process is to automate the Inky Frame to refresh the image every day at a certain time. This is where I ran into some trouble.\nThe Inky Frame will run anything saved as main.py when it starts up. If main.py is set to:\n\n#run showtimes_from_web.py on start-up\nwith open(\"showtimes_from_web.py\") as f:\n    exec(f.read())\n\nthen my script showtimes_from_web.py will run on start-up, which pulls down the jpg from the GitHub page and displays it on the screen. The screen will start up when it is plugged in to USB power or when the battery pack is turned on. However, I don’t want to have to start up the screen manually each day, and I also don’t want to leave it plugged in all the time, so I need to find a way to get it to refresh itself while on battery power.\nI did a bunch of searching, and there are some helper functions out there that seemed promising.\nI tried a bunch of things first. I tried adding inky_frame.sleep_for(1) to main.py which should theoretically cause it to go to sleep for a minute and then start back up, but that didn’t trigger another run of main.py. I also tried adding this to the showtimes_from_web.py script itself, but that also didn’t work. I tried running another gc.collect() at the end of showtimes_from_web.py in order to ensure that as much of the RAM was available as possible, but that also didn’t work. I tried to find a way to “close” the jpg (the showtimes_from_web.py script has an open_file command, so I figured, maybe it needs to be closed again in order for the script to truly terminate), but it doesn’t seem to be needed because it looks like the decode function called directly after open_file contains a closing function within it.\nIn order to see if the sleep_for() function does wake the frame back up after it sleeps, I tried putting it at the beginning of the main.py function instead of at the end. It does indeed wake back up and continue running main.py. I thought there might be some issue with the showtimes_from_web.py fully finishing and perhaps the sleep_for() script never actually gets executed when it is at the end of main.py. One indicator that the script isn’t fully finishing is that the busy symbol on the screen doesn’t go away after the screen is refreshed.\nI tried following this blog using timers but this also didn’t work. I could see the timer was working but it didn’t spark a refresh, which was more evidence that there is an issue with the showtimes script fully finishing.\nThen I noticed that there was a file on my Inky Frame called state.json that seemed to indicate the script was continuing to run. I tried deleting this file by using inky_helper.clear_state(). the console. After doing this and including sleep_for() at the end of main.py, I was able to trigger a refresh when it was plugged in to USB power! But on battery power, it still didn’t work.\nAfter months of googling and trying new things, I saw that others have posted about having the same sort of issue on both the Pimoroni forums and in their GitHub issues. In that thread someone posts a patch for micropython that they say solves the issue. I tried installing this patch, and it does seem like it prevents the showtimes script from getting stuck and not fully finishing. However, after running sleep_for(), the script just stops and doesn’t start main.py from the beginning as I want.\nI reread the thread on the forum a few times and noticed that the original poster actually executes their graphics.update() and sleep_for() commands within a while loop. When I add this loop to my own script, like this:\n\n#updated main.py\nimport inky_frame\n\nwhile True:\n  \n    with open(\"showtimes_from_web.py\") as f:\n        exec(f.read())\n        \n    inky_frame.sleep_for(1)\n\n…it does successfully cause a refresh after the screen sleeps! We’re getting closer! However after the first refresh, I got a strange EPERM error. After further copying the techniques of the original poster and adding some error logging to my scripts, I saw the error was occurring at the uos.mount() command in showtimes_from_web.py at the second run-through. I found the documentation for uos, and saw that uos.mount() throws this EPERM error when the file system is already mounted. I tried adding a uos.umount() command at the very end of the showtimes_from_web.py script, and this seems to have solved the issue! The screen refreshes continuously!\nFinally, the moment of truth…does it refresh continuously when on battery power? I unplug the frame, turn on the battery pack, perform a reset (by holding down the A, E, and reset buttons), and wait…and it works! The screen refreshes on its own!\n\n\n\n\nIt me\n\n\n\nAll of the scripts that I used on the Inky Frame (these are the only ones loaded–I deleted all other default examples and libraries that it comes with) are in the inky_frame_scripts folder of the GitHub repository. As a last step, I increased the sleep time to 60 minutes with sleep_for(60). Hopefully this doesn’t drain the battery too quickly. I may further increase it later.\nNow I’ll finally be able to sleep at night. Until I come up with another silly idea."
  },
  {
    "objectID": "posts/webscraping-showtimes-update/index.html",
    "href": "posts/webscraping-showtimes-update/index.html",
    "title": "Update on the Inky Frame",
    "section": "",
    "text": "This is a follow-up to my previous post about creating my own movie showtimes board with an inky frame.\nThe big question mark left after I beat the final boss of my inky frame project was how long the screen would continue to work without intervention. To date, here’s what’s happened so far.\nI finished the project on 2/19. On 2/29, the screen got stuck with the “thinking” light left on. I turned it off and back on and then reset the screen by pushing A + E + reset, and then it started working again. I figured this was some network issue that caused it to freeze up.\nI came back from a vacation in March, and saw that the screen was stuck on the showtimes for 3/12. The thinking light wasn’t on this time. I checked the repository, and the showtime images were continuing to generate each day, so the problem was definitely with the screen itself. I tried to turn it on and off again and reset it, but that didn’t fix the issue. This indicated to me the batteries had probably died. I changed the batteries on 3/20 and reset the screen, and it started working again.\nSo this means that the batteries lasted for about 3 weeks worth of hourly refreshes. They weren’t a totally fresh set of batteries because they’re the same ones I used for all my testing, so it’s hard to know exactly how long a totally fresh set would last. I also think that the refresh rate is probably too high, so I’m going to try reducing it to every 2 hours and see how that goes.\n\nUpdate 2024-04-21\nMore dead batteries on 4/17! So it seems like reducing the refresh rate to every 2 hours gave me about another week of screen time, 4 weeks total.\nI’ll try to reduce it further to every 12 hours and see what happens. Start the clock: recharged the batteries and reset the screen at 5:35pm today."
  },
  {
    "objectID": "posts/rstudio-code-snippets/index.html",
    "href": "posts/rstudio-code-snippets/index.html",
    "title": "I love RStudio code snippets",
    "section": "",
    "text": "Just a quick tip that keeps your life organized and saves you the pain of copy/pasting from old scripts: RStudio allows you to make your own custom shortcuts to generate code snippets that you use often. You can see all the code snippets and make your own by going to Tools &gt; Edit Code Snippets in the RStudio IDE. From there you select the file type that the snippet is used for, add/remove/edit the snippets, and hit save.\nI have two main uses for these snippets: to create a header and outline for my R scripts, and to create the YAML header for quarto blog posts (like this one!)\nMy snippet for an R script header looks like this:\n\nsnippet header\n    ## ------------------------------------------------------ ##\n    ##\n    ## Purpose of script: ${1:purpose}\n    ##\n    ## Author: Lindsay Lee\n    ## Email: me@lindsayevanslee.com\n    ##\n    ## Date Created: `r paste(Sys.Date())`\n    ##\n    ##\n    ## ------------------------------------------------------ ##\n    ##\n    ## Notes:\n    ##    - ${2:note}\n    ##   \n    ##\n    ## ------------------------------------------------------ ##\n    \n    \n    \n    \n    ## setup --------------------------------\n    \n    \n    \n    \n    \n    \n    ## read data ----------------------------\n    \n    \n    \n    \n    \n    \n    ## wrangle data -------------------------\n    \n    \n    \n    \n    \n    \n    ## print output -------------------------\n    \n    \n\nEach snippet starts with snippet and then the name of the snippet–in this case, header. Then below it on indented lines you write the code that makes up the snippet. You can also embed variables like I have done for the Purpose and the Notes–these will be areas that your cursor will jump to when the snippet generates. You can also add in-line R code, like I’ve done for the date. Then in any R script you can execute this R script by beginning to type the snippet name, and then hitting Tab when it comes up on the text prediction options:\n\n\n\nText prediction options? Whatever this is called\n\n\nMy snippet for the YAML header for a quarto blog post is like this:\n\nsnippet post\n    ---\n    title: \"\"\n    description: \"\"\n    date: \"\"\n    draft: true\n    #image: \n    image-alt: \"\"\n    categories: []\n    jupyter: python3\n    engine: knitr\n    execute:\n        eval: false\n    ---\n\nThis snippet needs to be saved under the Markdown filetype. Then in any qmd file, type the name of the snippet, hit Shift+Tab and the header will generate! I’ll never need to google this nonsense ever again."
  },
  {
    "objectID": "posts/power-bi-custom-map/index.html",
    "href": "posts/power-bi-custom-map/index.html",
    "title": "Drawing a custom map for Power BI",
    "section": "",
    "text": "In Power BI it’s fairly easy to generate a map with location data that fits typical geographical boundaries like countries or states. If you want to draw a very custom map, it becomes more difficult. This is a way I figured out that seems much more complicated than it needs to be. I’m sure (I hope) there is an easier way that I’ll discover later.\nCurrently Power BI has multiple built-in mapping visualizations. You can draw custom shapes with the “Shape Map”, but it will be on a blank white background. I wanted my map to lay on top of a typical street map. The ArcGIS visualization makes this possible.\nIf you have an ArcGIS license, you can draw your custom maps within ArcGIS itself and access them via Power BI. This didn’t work for me for a couple reasons: 1. I didn’t have a license, and 2. I don’t know if you can connect your data in Power BI to reference layers you create within ArcGIS. So that makes I need to find a way to have custom location data within Power BI formatted in such a way that it is parseable by the ArcGIS visualization. After lots of digging (ArcGIS’s documentation is lacking), I found that custom shapes can be read from Power BI data in an “EsriJSON format”.\nFirst, I drew my map in Google Earth. Start a new project (it works best in Chrome), and click “New feature” -&gt; “Draw line or shape”.\n\nTrace out your shape, and give it a name. When you’ve finished drawing your map, go to the “…” menu and click “Export as KML file”. I don’t really know what a KML is, but from what I can tell it’s a map format that Google likes to use.\n\nNext, the KML file needs to be converted to a form of JSON called GeoJSON. Again, don’t ask me what a GeoJSON is, but from context clues I’m gonna say it’s a JSON for geographic data.\n\n#open necessary libraries\nlibrary(sf)\nlibrary(tidyverse)\n\n#read in kml file\nmap_geo &lt;- sf::st_read(\"Example Project.kml\")\n\n#spit it back out again as a GeoJSON\nmap_geo %&gt;% \n  st_zm() %&gt;% #remove the Z dimension from the object\n  st_write(\"Example Project.geojson\")\n\nGeoJSON isn’t good enough for finicky ArcGIS/Power BI however, so we need to do a bit more wrangling to create a table that has shape data in an EsriJSON format. This website and this question on the ArcGIS forum helped me figure out what this mysterious EsriJSON needed to look like.\n\n#open necessary libraries\nlibrary(jsonlite)\nlibrary(tidyverse)\n\n#read in geojson file\nlist_json &lt;- read_json(\"Example Project.geojson\")\n\n#wrangle into EsriJSON format\ndf_parsed &lt;- list_json$features %&gt;%\n  map_dfr(.f = function(lst_elm) {\n    lst_elm %&gt;%\n      enframe() %&gt;%\n      pivot_wider()\n  }) %&gt;%\n  unnest_wider(properties) %&gt;%\n  select(-type) %&gt;%\n  unnest_wider(geometry) %&gt;%\n  mutate(coordinates = unlist(coordinates, recursive = FALSE)) %&gt;%\n  mutate(coordinates = map(coordinates, toJSON, digits = 20)) %&gt;%\n  mutate(coordinates = as.character(coordinates)) %&gt;%\n  mutate(coordinates = str_replace(coordinates, \"\\\\]$\", '\\\\]\\\\}')) %&gt;%\n  mutate(coordinates = str_replace(coordinates, \"\\\\[\", '\\\\{\"rings\": \\\\[')) %&gt;%\n  mutate(coordinates = str_replace_all(coordinates, \"\\\\],\\\\[\", \",\"))\n\n\n#print csv with EsriJSON column\nwrite_csv(df_parsed, file = \"Example Project.csv\")\n\nFinally, load this csv file into your Power BI report, put an ArcGIS visualization on your report canvas, and use the coordinates column in the “Location” field to create your custom map.\n\nIf you create relationships between this table and other data in your model, then you can overlay more data on this map via coloring, sizing, and tooltips.\nThat’s it! Easy! I’m gonna go take a nap."
  },
  {
    "objectID": "posts/font-design/index.html",
    "href": "posts/font-design/index.html",
    "title": "Designing a custom font (with emojis)",
    "section": "",
    "text": "Inspired by my sister’s awesome PhD work in Medieval French, I have been playing around with designing a custom font. My latest experimentation is in this font-test GitHub repo and is published to an accompanying GitHub pages site, which you can see here:"
  },
  {
    "objectID": "posts/font-design/index.html#software",
    "href": "posts/font-design/index.html#software",
    "title": "Designing a custom font (with emojis)",
    "section": "Software",
    "text": "Software\nI am using Glyphs 3 for creating this font. Glyphs is a proprietary font design program for Mac that seems to be one of the most popular ones. They have student pricing and also a “mini” version that isn’t as expensive. I think you could do basically everything I have done so far with the mini version, except for the emojis.\nI am using Flow for sketching glyphs."
  },
  {
    "objectID": "posts/font-design/index.html#some-references-that-helped-me",
    "href": "posts/font-design/index.html#some-references-that-helped-me",
    "title": "Designing a custom font (with emojis)",
    "section": "Some references that helped me",
    "text": "Some references that helped me\nGlyphs has some pretty good documentation, and there are also some good videos on YouTube to help you get started:\n\nDrawing good paths\nDanielNisbet on Youtube\nCreating an Apple color font\nVertical metrics"
  },
  {
    "objectID": "posts/font-design/index.html#steps",
    "href": "posts/font-design/index.html#steps",
    "title": "Designing a custom font (with emojis)",
    "section": "Steps",
    "text": "Steps\n\nGetting started\n\nCreate new font in Glyphs\nSet parameters under Font Info: Units per Em, Ascender, Descender, etc\n\n\n\nLower case letters\n\nMake new components to share between glyphs by creating new glyphs with names starting with _\nDraw the letters, and right click to add components\n\n\n\nUpper case letters\n\nSet custom Exports parameters:\n\n\nDisable Subroutines (on): needed because the capitals are very complicated\n\n\nCopy sketches into glyph, and set size\nUse “Trace Image” plugin to trace the image\nClean up\nDelete image\n\n\n\nEmojis\n\nSet custom Font parameters:\n\n\nUse Typo Metrics (on)\n\n\nSet custom Masters parameters:\n\n\nhheaAscender, hheaDescender, hheaLineGap: needed to avoid clipping\n\n\nSet custom Export parameters:\n\n\nExport sbix Table: needed for emojis to render\nSBIX to SVG: needed to increase support for color font\n\n\nCreate new glyph called “_emoji_origin”, set width to be the same as the UPM for the font, and put small path in the bottom left corner where the emoji’s bottom left corner will be anchored\nCreate new glyph with the emoji needed (either generate from glyph list or add directly by using the exact name or unicode)\nAdd component _emoji_origin to emoji and decompose\nPrepare image files for emoji:\n\n\nOriginal image should be square png with transparent background\nCreate a copies of images with different resolutions. For example set first image as resolution 512, with a height and width that works when you paste image into the glyph. Next image should have half resolution (256) and half height and width\nSet names of files as all “glyphname resolution.png”, eg “slightlySmilingFace 512.png”\n\n\nUse script Add sbix Images to Font to batch-import your emoji images\n\n\nThis is a mekkablue script that can be added from Plugin Manager -&gt; Scripts\nIf it doesn’t work, you can read error messages by opening the Macro Panel"
  },
  {
    "objectID": "posts/font-design/index.html#next-steps",
    "href": "posts/font-design/index.html#next-steps",
    "title": "Designing a custom font (with emojis)",
    "section": "Next steps",
    "text": "Next steps\n\nMake the font more cohesive\nDraw better\nMake more emojis\nFigure out something cool to do with this"
  },
  {
    "objectID": "posts/webscraping-screenshots/index.html",
    "href": "posts/webscraping-screenshots/index.html",
    "title": "Webscraping screenshots with Selenium",
    "section": "",
    "text": "My team at work maintained a dashboard related to COVID-19 that included screenshots of graphs online that needed to be updated daily. I had recently taken a little LinkedIn Learning course called Web Scraping with Python and thought this could be a cool opportunity to try that out. The course doesn’t really talk about webscraping screenshots, but it helped give me some of the foundational knowledge and vocabulary.\nAfter a lot of trial and error, here is an small script I came up with. This script cycles through a python dictionary of directions to specific locations, captures the screenshot, and saves it. One element of the dictionary contains the URL where the screenshot is, an XPATH direction to the location of the screenshot on the page, the frame number, and the name of the file that it should be saved to. The XPATH may give you a list of multiple web elements (or “frames”), so the frame number is needed to tell the program which element of that list to save.\nThis script doesn’t work exactly anymore, because these web pages have changed. That’s one major drawback: it’s very unstable and sensitive to change. And because of that, we didn’t end up implementing this at work. But this same script structure could be used for different purposes in the future.\n\n##import packages -----------\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom time import sleep\nfrom datetime import date\n\n\n## set up --------\n\n#open driver\ndriver = webdriver.Safari()\n\n#create function to see full page\nS = lambda X: driver.execute_script('return document.body.parentNode.scroll'+X)\n\n#get today's date\ntoday = date.today().strftime(\"%Y-%m-%d\")\n\n#dictionary of screenshots to capture\ndict_urls = [\n    {\n        \"id\": 1, \n        \"url\": 'https://insight.livestories.com/s/v2/1-2-case-counts/c4f65175-2433-47b7-b112-d62cf719af71',\n        \"xpath\": \"//main//iframe\",\n        \"frame_number\": 11,\n        \"filename\": 'weekly-covid-19-test-positivity-rate'\n    },\n        {\n        \"id\": 2, \n        \"url\": 'https://insight.livestories.com/s/v2/1-4-geographic-data/6bb3072d-e622-4b84-9555-7b0ef390b354',\n        \"xpath\": \"//main//iframe\",\n        \"frame_number\": 0,\n        \"filename\": '14-day-testing-rate-per-100000-pop'\n    },\n        {\n        \"id\": 3, \n        \"url\": 'https://insight.livestories.com/s/v2/1-4-geographic-data/6bb3072d-e622-4b84-9555-7b0ef390b354',\n        \"xpath\": \"//main//iframe\",\n        \"frame_number\": 1,\n        \"filename\": '14-day-case-rate-per-100000-pop'\n    },\n        {\n        \"id\": 4, \n        \"url\": 'https://insight-editor.livestories.com/s/v2/1.1-data-dashboard/5d1c9c7a-1eb4-4e9c-82ab-efeaa6258cad',\n        \"xpath\": \"//div[contains(@class, 'css-1bedmrb') and contains(@class, 'erxya8v2')]/div[contains(@class, 'css-rpv578') and contains(@class, 'ezdhjma0')]\",\n        \"frame_number\": 9,\n        \"filename\": 'hrts'\n    }\n    ]\n\n\n## screenshots ------------------------\n\n## loop through dictionary of screenshots\nfor i in range(len(dict_urls)):\n    #go to URL\n    driver.get(url = dict_urls[i]['url'])\n    sleep(3)\n\n    #set window size to full page\n    driver.set_window_size(S('Width'),S('Height')) # May need manual adjustment   \n    sleep(3)\n\n    #find set of frames\n    myframe = driver.find_elements(By.XPATH, dict_urls[i]['xpath'])\n\n    #print needed figure\n    myframe[dict_urls[i]['frame_number']].screenshot(dict_urls[i]['filename'] + \"_\" + today + '.png')\n\n## close driver ----------------------------------\ndriver.quit()\nprint(\"end...\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A blog of technical trial and error",
    "section": "",
    "text": "Get started with conda\n\n\n\n\n\n\n\npython\n\n\nconda\n\n\nworkflow\n\n\n\n\nI’ve put off learning this for too long\n\n\n\n\n\n\nApr 5, 2024\n\n\nLindsay Lee\n\n\n\n\n\n\n  \n\n\n\n\nI love RStudio code snippets\n\n\n\n\n\n\n\nrstudio\n\n\nr\n\n\nquarto\n\n\nworkflow\n\n\n\n\nI don’t love copy/pasting\n\n\n\n\n\n\nMar 31, 2024\n\n\nLindsay Lee\n\n\n\n\n\n\n  \n\n\n\n\nAnalyze health data from the Apple Watch\n\n\n\n\n\n\n\nhealth\n\n\napple watch\n\n\nr\n\n\npython\n\n\n\n\nBeing #extra at my doctor’s appointment\n\n\n\n\n\n\nMar 30, 2024\n\n\nLindsay Lee\n\n\n\n\n\n\n  \n\n\n\n\nUpdate on the Inky Frame\n\n\n\n\n\n\n\nwebscraping\n\n\npython\n\n\nraspberry pi\n\n\nautomation\n\n\n\n\nSpoiler alert: the batteries died\n\n\n\n\n\n\nMar 21, 2024\n\n\nLindsay Lee\n\n\n\n\n\n\n  \n\n\n\n\nMaking my own box office sign with Scrapy and an Inky Frame\n\n\n\n\n\n\n\nwebscraping\n\n\npython\n\n\nraspberry pi\n\n\nautomation\n\n\n\n\nThe algorithm got me again\n\n\n\n\n\n\nFeb 19, 2024\n\n\nLindsay Lee\n\n\n\n\n\n\n  \n\n\n\n\nDrawing a custom map for Power BI\n\n\n\n\n\n\n\nmaps\n\n\npower bi\n\n\nr\n\n\n\n\nIt took like 4 different programs but we did it.\n\n\n\n\n\n\nMar 26, 2023\n\n\nLindsay Lee\n\n\n\n\n\n\n  \n\n\n\n\nDesigning a custom font (with emojis)\n\n\n\n\n\n\n\nfonts\n\n\n\n\nInspired by my sister’s awesome PhD work in Medieval French, I have been playing around with designing a custom font.\n\n\n\n\n\n\nMar 26, 2023\n\n\nLindsay Lee\n\n\n\n\n\n\n  \n\n\n\n\nWebscraping screenshots with Selenium\n\n\n\n\n\n\n\nwebscraping\n\n\npython\n\n\n\n\nNo more repetitive copy-pasting!\n\n\n\n\n\n\nMar 26, 2023\n\n\nLindsay Lee\n\n\n\n\n\n\nNo matching items"
  }
]