---
title: "Webscraping movie showtimes with Scrapy"
draft: true
description: "The algorithm got me again"
#date: ""
#image: 
#image-alt: ""
categories: [webscraping, python, raspberry pi]
jupyter: python3
engine: knitr
execute:
    eval: false
---

I'm a flawed human being and therefore susceptible to ads I receive on the internet. One day I was scrolling and stumbled upon this little gadget by Pimoroni: the [Inky Frame 7.3\"](https://shop.pimoroni.com/products/inky-frame-7-3?variant=40541882056787), a fun little e-ink screen that you can program with micropython. I bought it without much a plan for what I would use it for, but thought it would be a fun excuse to practice my python skills. I soon got the idea to combine my loves: I spend all my free time and money at the [Belcourt Theatre](https://www.belcourt.org) in Nashville, and thought it would be cool to use the screen as a little display that shows the showtimes for the day.

Accomplishing this means several things have to happen:

1.  Webscrape the showtimes from the theater's website
2.  Format the showtimes into an image that works well on the Inky Frame display
3.  Push the image output to the Inky Frame
4.  Schedule all of the above to run daily automatically

Here I go through what I did for each of these steps. All the code is available on [GitHub](https://github.com/lindsayevanslee/inky-frame).

# Web scrape the showtimes

To webscrape the showtimes, I used the popular python package `Scrapy`. There is a really useful and fun course on LinkedIn Learning by Ryan Mitchell called ["Web Scraping with Python"](https://www.linkedin.com/learning/web-scraping-with-python/hello-world-with-scrapy?u=103732282), which is where I first learned how to do this. She also has a book ["Web scraping with Python"](https://www.oreilly.com/library/view/web-scraping-with/9781491985564/) that is super informative. I'll leave most of the detail to her, but here is the gist:

First install `Scrapy`:

```{bash}
pip install Scrapy
```

Then you initialize a new project like so:

```{bash}
scrapy startproject belcourt
```

Navigate to the new project folder and initialize a spider (a "spider" is the program that will do all the scraping that you specify). Here I'm creating a spider called `showtimes` that will scrape the website `belcourt.org`:

```{bash}
cd belcourt
scrapy genspider showtimes belcourt.org
```

In the `items.py` script that is generated, I defined the structure of the output that I wanted by defining a new class called `BelcourtItem`.

```{python}
import scrapy

class BelcourtItem(scrapy.Item):
    # define the fields for your item here like:
    # name = scrapy.Field()
    currenttime = scrapy.Field()
    date = scrapy.Field()
    shows = scrapy.Field()
```

In the `showtimes.py` script in the `spiders` folder, specify which content from the website should be pulled into your output object of class `BelcourtItem`. This involves inspecting the html of the website and finding the relevant elements. See Ryan Mitchell's course/book for tips on how to do this. I also suggest learning more about searching for HTML elements with XPATH--[this YouTube video](https://www.youtube.com/watch?v=NhG__BL8zFo&list=PLSao4Yl0-ZqMIEG604vsNJc1i5X8YUDar&index=1) was the best resource I've come across.

To run the spider, navigate the console to the `spiders` folder and run spider like below. This will print the output to a json file called `output_showtimes.json`:

```{bash}
cd belcourt/spiders
scrapy runspider showtimes.py -O output_showtimes.json
```

You can see what this json file looks like in my GitHub repository.

Voila! Easy! Now we need to take the data from this json file and turn it into a fairly attractive jpg.

# Format the output into an image

Converting this json into a jpg mostly involved getting familiar with the `Pillow` python package. It can be installed like so:

```{bash}
pip install Pillow
```

The script I wrote is called `belcourt_generate_image.py`, and you can find it in the GitHub repository. 

First you read in the json output produced by the spider. Then specify some basics like the dimensions, title and subtitle and fonts. The dimensions match what is specified by Pimoroni in their ["Getting Started with Inky Frame"](https://learn.pimoroni.com/article/getting-started-with-inky-frame) resource. I read the fonts directly from ttf files which are also loaded into the repository. I also loaded the Belcourt logo so I could use it in my output.

The rest of the script is essentially telling python where exactly to place the different elements of the image. Finally, the output is saved to a jpg. One important note is that it is important that the resulting jpg must not be progressive. The frame can't handle it otherwise for some reason:

```{python}
background.save('result.jpg', progressive = False)
```

Now that we've got a jpg, time to get it on the screen!

# Load image into Inky Frame

Here is where we start getting into slightly uncharted territory. Pimoroni provides some nice guides and templates for displaying content on the screen. I first followed [this guide](https://learn.pimoroni.com/article/getting-started-with-inky-frame#displaying-images) to display a static image on the screen that was loaded directly into memory. That's not good enough though, because we need the screen to load the jpg via the web. Luckily they have [another example](https://github.com/pimoroni/pimoroni-pico/blob/main/micropython/examples/inky_frame/inky_frame_xkcd_daily.py) that does something similar. I adapted this script into my own version `showtimes_from_web.py`, available in the GitHub repository. This script requires wifi credentials saved in a `secrets.py` file, as described in the Pimoroni guide above. It also requires a `network_manager.py` file, available from [Pimoroni's example GitHub](https://github.com/pimoroni/pimoroni-pico/tree/main/micropython/examples/common). It also requires a micro SD card be installed, which luckily comes with the Inky Frame. 

Most importantly, the script needs a URL to access the image from. First I tried to use the link to the jpg in the repository: `https://github.com/lindsayevanslee/inky-frame/blob/main/belcourt/result.jpg?raw=true`. However this link leads to a redirect, which the `urllib` micropython package used by the Inky Frame cannot handle. Therefore we need a stable, direct link to the jpg. Luckily GitHub offers the ability to create a webpage for your repository using GitHub Pages. This can be configured by going to the settings for the repository, then going to "Pages". I chose to use "GitHub Actions" as the source and the "main" branch as the branch to publish to. By default `README.md` will be used as the main page for the resulting site. Link to the jpg in the `README` like so:

```{markdown}
# inky-frame
Code powering my shiny new Inky Frame

Here is the latest output:
![Image with latest showtimes from the Belcourt Theatre](belcourt/result.jpg)
```

This will load the jpg to the GitHub Page, and then you can copy the jpg link from there for use in the `showtimes_from_web.py` script. 

# Automate to run daily

There are two aspects of automation that need to be implemented: automatically updating the jpg every day with the day's showtimes, and automating the refresh of the inky frame to display the new jpg.

## Automate the jpg update

GitHub Actions can be used to execute scripts on a schedule and make commits to the repository. I used [this guide](https://www.python-engineer.com/posts/run-python-github-actions/) to set up a GitHub Action that would run the spider and generate the jpg every day at 6am. The syntax for defining the schedule is called cron, and [this website](https://crontab.guru) is super helpful for figuring out how to configure the cron syntax to do what you want. 

This GitHub Action requires giving the workflows read/write permissions by enabling: Settings \> Actions \> General \> Workflow Permissions \> Read and write permissions. The workflow is defined by a YAML file that I've called `.github/workflows/actions.yml` in the GitHub repository. The script runs the spider, runs the `belcourt_generate_image.py` script, and then commits the resulting jpg to the repository.

A second GitHub Action is needed to update the GitHub Pages deployment every time the jpg is updated. By going to Settings \> Pages, you can configure the deployment of the webpage. GitHub automatically provides an Action template for you, and there is additional detail in the [documentation](https://docs.github.com/en/pages/getting-started-with-github-pages/configuring-a-publishing-source-for-your-github-pages-site). One change I made to the YAML file was to schedule the deployment to run after the first action that updates the jpg. I wanted to do this by triggering the deployment after the new changes were committed to the repository, but I couldn't get it to work. I found [this blog](https://jahed.dev/2021/04/24/triggering-github-actions-from-commits-by-other-actions/) that was trying to do the same thing, but I couldn't figure it out. Instead I scheduled the deployment to run half an hour after the first action, which should be enough time for it to finish.


## Automate the inky frame refresh

Set showtimes_from_web.py script to run on startup by linking to it within main.py

on battery power => turning on and pressing a button causes main.py to run, therefore refreshing the image

how to get have main.py run daily on battery power? tried adding inky_frame.sleep_for(1) to main.py, but that doesn't trigger another run of main.py. Tried adding this to the showtimes script itself, also didnt work. try running another gc.collect() at the en dof showtimes script, also didn't work. tried to find a way to close a jpeg, doesn't seem to be needed because it looks like decode contains a closing function 

putting sleep. functionb efore showtimes does indeed start a refresh, so having at the end of main.py should work . so seems like there is some issue with the script fully finishing

Also tried this: https://www.upesy.com/blogs/tutorials/timer-raspberry-pi-pico-with-micropython#
clearly timer is working but it doesn't spark a refresh. points to another issue with showtimes sccript fully finishing

deleted teh file state.json by using clear_state in teh console which looks like it's used by the original main.py to remember. which example script to run. after doing this, the busy symbol goes away and having the sleep command at the end of main.py seems to work!!!!!!!!!!!! trying also adding clear_state() to main.py to make sure it's deleted before and after runtime. this doesn't seem to work. but we are getting closer.......next try not running app wiht launch_app but back to original way


