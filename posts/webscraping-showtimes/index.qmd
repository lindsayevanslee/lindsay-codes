---
title: "Webscraping movie showtimes with Scrapy"
draft: true
description: "The algorithm got me again"
#date: ""
#image: 
#image-alt: ""
categories: [webscraping, python, raspberry pi]
jupyter: python3
engine: knitr
execute:
    eval: false
---

I'm a flawed human being and therefore susceptible to ads I receive on the internet. One day I was scrolling and stumbled upon this little gadget by Pimoroni: the [Inky Frame 7.3\"](https://shop.pimoroni.com/products/inky-frame-7-3?variant=40541882056787), a fun little e-ink screen that you can program with micropython. I bought it without much a plan for what I would use it for, but thought it would be a fun excuse to practice my python skills. I soon got the idea to combine my loves: I spend all my free time and money at the [Belcourt Theatre](https://www.belcourt.org) in Nashville, and thought it would be cool to use the screen as a little display that shows the showtimes for the day.

Accomplishing this means several things have to happen:

1.  Webscrape the showtimes from the theater's website
2.  Format the showtimes into an image that works well on the Inky Frame display
3.  Push the image output to the Inky Frame
4.  Schedule all of the above to run daily automatically

Here I go through what I did for each of these steps. All the code is available on [GitHub](https://github.com/lindsayevanslee/inky-frame).

# Web scrape the showtimes

To webscrape the showtimes, I used the popular python package `Scrapy`. There is a really useful and fun course on LinkedIn Learning by Ryan Mitchell called ["Web Scraping with Python"](https://www.linkedin.com/learning/web-scraping-with-python/hello-world-with-scrapy?u=103732282), which is where I first learned how to do this. She also has a book ["Web scraping with Python"](https://www.oreilly.com/library/view/web-scraping-with/9781491985564/) that is super informative. I'll leave most of the detail to her, but here is the gist:

First install `Scrapy`:

```{bash}
pip install Scrapy
```

Then you initialize a new project like so:

```{bash}
scrapy startproject belcourt
```

Navigate to the new project folder and initialize a spider (a "spider" is the program that will do all the scraping that you specify). Here I'm creating a spider called `showtimes` that will scrape the website `belcourt.org`:

```{bash}
cd belcourt
scrapy genspider showtimes belcourt.org
```

In the `items.py` script that is generated, I defined the structure of the output that I wanted by defining a new class called `BelcourtItem`.

```{python}
import scrapy

class BelcourtItem(scrapy.Item):
    # define the fields for your item here like:
    # name = scrapy.Field()
    currenttime = scrapy.Field()
    date = scrapy.Field()
    shows = scrapy.Field()
```

In the `showtimes.py` script in the `spiders` folder, specify which content from the website should be pulled into your output object of class `BelcourtItem`. This involves inspecting the html of the website and finding the relevant elements. See Ryan Mitchell's course/book for tips on how to do this. I also suggest learning more about searching for HTML elements with XPATH--[this YouTube video](https://www.youtube.com/watch?v=NhG__BL8zFo&list=PLSao4Yl0-ZqMIEG604vsNJc1i5X8YUDar&index=1) was the best resource I've come across.

To run the spider, navigate the console to the `spiders` folder and run spider like below. This will print the output to a json file called `output_showtimes.json`:

```{bash}
cd belcourt/spiders
scrapy runspider showtimes.py -O output_showtimes.json
```

You can see what this json file looks like in my GitHub repository.

Voila! Easy! Now we need to take the data from this json file and turn it into a fairly attractive jpg.

# Format the output into an image

Converting this json into a jpg mostly involved getting familiar with the `Pillow` python package. It can be installed like so:

```{bash}
pip install Pillow
```

The script I wrote is called `belcourt_generate_image.py`, and you can find it in the GitHub repository. 

First you read in the json output produced by the spider. Then specify some basics like the dimensions, title and subtitle and fonts. The dimensions match what is specified by Pimoroni in their ["Getting Started with Inky Frame"](https://learn.pimoroni.com/article/getting-started-with-inky-frame) resource. I read the fonts directly from ttf files which are also loaded into the repository. I also loaded the Belcourt logo so I could use it in my output.

The rest of the script is essentially telling python where exactly to place the different elements of the image. Finally, the output is saved to a jpg. One important note is that it is important that the resulting jpg must not be progressive. The frame can't handle it otherwise for some reason:

```{python}
background.save('result.jpg', progressive = False)
```

Now that we've got a jpg, time to get it on the screen!

# Load image into Inky Frame

Here is where we start getting into slightly uncharted territory. Pimoroni provides some nice guides and templates for displaying content on the screen. I first followed [this guide](https://learn.pimoroni.com/article/getting-started-with-inky-frame#displaying-images) to display a static image on the screen that was loaded directly into memory. That's not good enough though, because we need the screen to load the jpg via the web. Luckily they have [another example](https://github.com/pimoroni/pimoroni-pico/blob/main/micropython/examples/inky_frame/inky_frame_xkcd_daily.py) that does something similar. I adapted this script into my own version `showtimes_from_web.py`, available in the GitHub repository. This script requires wifi credentials saved in a `secrets.py` file, as described in the Pimoroni guide above. It also requires a `network_manager.py` file, available from [Pimoroni's example GitHub](https://github.com/pimoroni/pimoroni-pico/tree/main/micropython/examples/common). It also requires a micro SD card be installed, which luckily comes with the Inky Frame. 

Most importantly, the script needs a URL to access the image from. First I tried to use the link to the jpg in the repository: `https://github.com/lindsayevanslee/inky-frame/blob/main/belcourt/result.jpg?raw=true`. However this link leads to a redirect, which the `urllib` micropython package used by the Inky Frame cannot handle. Therefore we need a stable, direct link to the jpg. Luckily GitHub offers the ability to create a webpage for your repository using GitHub Pages. This can be configured by going to the settings for the repository, then going to "Pages". I chose to use "GitHub Actions" as the source and the "main" branch as the branch to publish to. By default `README.md` will be used as the main page for the resulting site. Link to the jpg in the `README` like so:

```{markdown}
# inky-frame
Code powering my shiny new Inky Frame

Here is the latest output:
![Image with latest showtimes from the Belcourt Theatre](belcourt/result.jpg)
```

This will load the jpg to the GitHub Page, and then you can copy the jpg link from there for use in the `showtimes_from_web.py` script. 

# Automate to run daily

load jpg to inky frame

https://www.python-engineer.com/posts/run-python-github-actions/ https://crontab.guru

GitHub Actions

Settings \> Actions \> General \> Workflow Permissions \> Read and write permissions

Use pimoroni example as basis for loading to screen: 

tried to load directly from raw jpg output in github repo, doesn't work--gives "can't read jpg" error

trying to load from a different website.....-\> unoptimized version just gets stuck and doesn't finish, using optimized version does work!!!!

link to github output -\> works! but repo must be public! (DUH)

maybe linking directly to github will work now with public repo -\> nope, gives error about redirects

try again to use unoptimized version, loading from github from a different site -\> works???

also works using the image copy of unoptimized version. so not sure why it wasn't working before.....

embedding an iframe to jpg link doesn't work

create github pages on inky frame repo and try to link to it from there -\> works! this seems like it would be the best final solution

need to adjust the github pages to trigger on each new commit
found this blog wanting to do the same thing: https://jahed.dev/2021/04/24/triggering-github-actions-from-commits-by-other-actions/
geting ssh key: https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent
setting repo secret: https://docs.github.com/en/actions/security-guides/using-secrets-in-github-actions
found email for actions-user by checking a job that ran and checkign otuput of "commit files" step: action@github.com

couldn' tget the sshkey thing to work, so will just schedule the action for after the other action finishes using cron

actually tried again, SSH using my email, making sure to paste all "as is" - includign ---BEGINNING --- and ---ENDING---- lines in private key, and the empty new line -> works! and hopefully should work when the spider runs, because according to this the email doesn't matter (it's just a comment): https://askubuntu.com/questions/801997/purpose-of-email-at-the-end-of-ssh-public-key

SSH didn't work, bring back schedule. had to completely delete SSH deploy key and secret for the github pages to update again

Set showtimes_from_web.py script to run on startup by linking to it within main.py

on battery power => turning on and pressing a button causes main.py to run, therefore refreshing the image

how to get have main.py run daily on battery power? tried adding inky_frame.sleep_for(1) to main.py, but that doesn't trigger another run of main.py. Tried adding this to the showtimes script itself, also didnt work. try running another gc.collect() at the en dof showtimes script, also didn't work. tried to find a way to close a jpeg, doesn't seem to be needed because it looks like decode contains a closing function 

putting sleep. functionb efore showtimes does indeed start a refresh, so having at the end of main.py should work . so seems like there is some issue with the script fully finishing

Also tried this: https://www.upesy.com/blogs/tutorials/timer-raspberry-pi-pico-with-micropython#
clearly timer is working but it doesn't spark a refresh. points to another issue with showtimes sccript fully finishing

deleted teh file state.json by using clear_state in teh console which looks like it's used by the original main.py to remember. which example script to run. after doing this, the busy symbol goes away and having the sleep command at the end of main.py seems to work!!!!!!!!!!!! trying also adding clear_state() to main.py to make sure it's deleted before and after runtime. this doesn't seem to work. but we are getting closer.......next try not running app wiht launch_app but back to original way


